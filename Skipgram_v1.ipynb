{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "mount_file_id": "1vvMjOLADhRBJ20vwhiH3IufE8qc-9qOQ",
      "authorship_tag": "ABX9TyMVVAhT2T9ExqY96NLDhQfV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiabet/Project_Market/blob/master/Skipgram_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey23ur3aUqBx",
        "outputId": "1416f8d3-1820-4e98-e7b2-9be0e47e89ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "stop_words = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()\n",
        "stop_words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zrrSTPPgUA8",
        "outputId": "493bc170-5551-46bc-95fd-19fb5a0e58eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['휴'],\n",
              " ['아이구'],\n",
              " ['아이쿠'],\n",
              " ['아이고'],\n",
              " ['어'],\n",
              " ['나'],\n",
              " ['우리'],\n",
              " ['저희'],\n",
              " ['따라'],\n",
              " ['의해']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "n6tbIc8HM_V0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "class word2vec(object):\n",
        "    def __init__(self):\n",
        "        self.N = 10\n",
        "        self.X_train = []\n",
        "        self.y_train = []\n",
        "        self.window_size = 1\n",
        "        self.alpha = 0.001\n",
        "        self.words = []\n",
        "        self.word_index = {}\n",
        "\n",
        "    def initialize(self,V,data):\n",
        "        self.V = V\n",
        "        self.W = np.random.uniform(-0.8, 0.8, (self.V, self.N))\n",
        "        self.W1 = np.random.uniform(-0.8, 0.8, (self.N, self.V))\n",
        "\n",
        "        self.words = data\n",
        "        for i in range(len(data)):\n",
        "            self.word_index[data[i]] = i\n",
        "\n",
        "\n",
        "    def feed_forward(self,X):\n",
        "        self.h = np.dot(self.W.T,X).reshape(self.N,1)\n",
        "        self.u = np.dot(self.W1.T,self.h)\n",
        "        #print(self.u)\n",
        "        self.y = softmax(self.u)\n",
        "        return self.y\n",
        "\n",
        "    def backpropagate(self,x,t):\n",
        "        e = self.y - np.asarray(t).reshape(self.V,1)\n",
        "        # e.shape is V x 1\n",
        "        dLdW1 = np.dot(self.h,e.T)\n",
        "        X = np.array(x).reshape(self.V,1)\n",
        "        dLdW = np.dot(X, np.dot(self.W1,e).T)\n",
        "        self.W1 = self.W1 - self.alpha*dLdW1\n",
        "        self.W = self.W - self.alpha*dLdW\n",
        "\n",
        "    def train(self,epochs):\n",
        "        for x in range(1,epochs):\n",
        "            self.loss = 0\n",
        "            for j in range(len(self.X_train)):\n",
        "                self.feed_forward(self.X_train[j])\n",
        "                self.backpropagate(self.X_train[j],self.y_train[j])\n",
        "                C = 0\n",
        "                for m in range(self.V):\n",
        "                    if(self.y_train[j][m]):\n",
        "                        self.loss += -1*self.u[m][0]\n",
        "                        C += 1\n",
        "                self.loss += C*np.log(np.sum(np.exp(self.u)))\n",
        "            print(\"epoch \",x, \" loss = \",self.loss)\n",
        "            self.alpha *= 1/( (1+self.alpha*x) )\n",
        "\n",
        "    def predict(self,word,number_of_predictions):\n",
        "        if word in self.words:\n",
        "            index = self.word_index[word]\n",
        "            X = [0 for i in range(self.V)]\n",
        "            X[index] = 1\n",
        "            prediction = self.feed_forward(X)\n",
        "            output = {}\n",
        "            for i in range(self.V):\n",
        "                output[prediction[i][0]] = i\n",
        "\n",
        "            top_context_words = []\n",
        "            for k in sorted(output,reverse=True):\n",
        "                top_context_words.append(self.words[output[k]])\n",
        "                if(len(top_context_words)>=number_of_predictions):\n",
        "                    break\n",
        "\n",
        "            return top_context_words\n",
        "        else:\n",
        "            print(\"Word not found in dictionary\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "import string\n",
        "\n",
        "def preprocessing(corpus):\n",
        "    okt = Okt()\n",
        "    training_data = []\n",
        "    sentences = corpus.split(\"-\")\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "        sentences[i] = sentences[i].strip()\n",
        "        words_and_tags = okt.pos(sentences[i])\n",
        "\n",
        "        filtered_words = [word for word, tag in words_and_tags\n",
        "                          if tag in ['Adverb', 'Verb', 'Adjective']\n",
        "                          and word not in stop_words]\n",
        "\n",
        "        x = [word.strip(string.punctuation) for word in filtered_words]\n",
        "        x = [word for word in filtered_words if len(x) > 1]\n",
        "        training_data.append(x)\n",
        "\n",
        "    return training_data\n",
        "\n",
        "\n",
        "def prepare_data_for_training(sentences,w2v):\n",
        "    data = {}\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            if word not in data:\n",
        "                data[word] = 1\n",
        "            else:\n",
        "                data[word] += 1\n",
        "    V = len(data)\n",
        "    data = sorted(list(data.keys()))\n",
        "    vocab = {}\n",
        "    for i in range(len(data)):\n",
        "        vocab[data[i]] = i\n",
        "\n",
        "    #for i in range(len(words)):\n",
        "    for sentence in sentences:\n",
        "        for i in range(len(sentence)):\n",
        "            center_word = [0 for x in range(V)]\n",
        "            center_word[vocab[sentence[i]]] = 1\n",
        "            context = [0 for x in range(V)]\n",
        "\n",
        "            for j in range(i-w2v.window_size,i+w2v.window_size):\n",
        "                if i!=j and j>=0 and j<len(sentence):\n",
        "                    context[vocab[sentence[j]]] += 1\n",
        "            w2v.X_train.append(center_word)\n",
        "            w2v.y_train.append(context)\n",
        "    w2v.initialize(V,data)\n",
        "\n",
        "    return w2v.X_train,w2v.y_train"
      ],
      "metadata": {
        "id": "XUz0og2iNRCo"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "\n",
        "training_data = preprocessing(corpus)\n",
        "w2v = word2vec()\n",
        "\n",
        "prepare_data_for_training(training_data,w2v)\n",
        "w2v.train(epochs)\n",
        "\n",
        "print(w2v.predict(\"좋아요\",10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZBBqP0bEWn8",
        "outputId": "5c7d6be0-6061-4fae-8721-16eb449d5cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  1  loss =  1371.791637051001\n",
            "epoch  2  loss =  1370.542136534754\n",
            "epoch  3  loss =  1369.3003470261356\n",
            "epoch  4  loss =  1368.0673793871215\n",
            "epoch  5  loss =  1366.8443071136012\n",
            "epoch  6  loss =  1365.6321607500129\n",
            "epoch  7  loss =  1364.4319228224065\n",
            "epoch  8  loss =  1363.2445233489614\n",
            "epoch  9  loss =  1362.0708359737293\n",
            "epoch  10  loss =  1360.9116747553094\n",
            "epoch  11  loss =  1359.767791627982\n",
            "epoch  12  loss =  1358.6398745389197\n",
            "epoch  13  loss =  1357.5285462519587\n",
            "epoch  14  loss =  1356.4343637963339\n",
            "epoch  15  loss =  1355.3578185282645\n",
            "epoch  16  loss =  1354.2993367641423\n",
            "epoch  17  loss =  1353.259280937047\n",
            "epoch  18  loss =  1352.2379512227478\n",
            "epoch  19  loss =  1351.2355875778921\n",
            "epoch  20  loss =  1350.2523721310922\n",
            "epoch  21  loss =  1349.2884318673148\n",
            "epoch  22  loss =  1348.3438415470625\n",
            "epoch  23  loss =  1347.4186268040166\n",
            "epoch  24  loss =  1346.5127673680047\n",
            "epoch  25  loss =  1345.6262003641098\n",
            "epoch  26  loss =  1344.7588236431927\n",
            "epoch  27  loss =  1343.9104991038487\n",
            "epoch  28  loss =  1343.0810559708812\n",
            "epoch  29  loss =  1342.2702940002139\n",
            "epoch  30  loss =  1341.4779865851349\n",
            "epoch  31  loss =  1340.703883743315\n",
            "epoch  32  loss =  1339.9477149684571\n",
            "epoch  33  loss =  1339.209191934349\n",
            "epoch  34  loss =  1338.4880110428123\n",
            "epoch  35  loss =  1337.7838558101062\n",
            "epoch  36  loss =  1337.0963990893322\n",
            "epoch  37  loss =  1336.4253051286526\n",
            "epoch  38  loss =  1335.7702314672415\n",
            "epoch  39  loss =  1335.1308306725934\n",
            "epoch  40  loss =  1334.5067519241213\n",
            "epoch  41  loss =  1333.897642449073\n",
            "epoch  42  loss =  1333.3031488176314\n",
            "epoch  43  loss =  1332.7229181045266\n",
            "epoch  44  loss =  1332.1565989250373\n",
            "epoch  45  loss =  1331.603842353267\n",
            "epoch  46  loss =  1331.0643027308065\n",
            "epoch  47  loss =  1330.5376383737268\n",
            "epoch  48  loss =  1330.0235121857327\n",
            "epoch  49  loss =  1329.5215921850975\n",
            "epoch  50  loss =  1329.0315519526785\n",
            "epoch  51  loss =  1328.5530710079695\n",
            "epoch  52  loss =  1328.0858351198465\n",
            "epoch  53  loss =  1327.6295365582323\n",
            "epoch  54  loss =  1327.1838742925027\n",
            "epoch  55  loss =  1326.7485541421395\n",
            "epoch  56  loss =  1326.3232888846344\n",
            "epoch  57  loss =  1325.9077983253974\n",
            "epoch  58  loss =  1325.501809333926\n",
            "epoch  59  loss =  1325.1050558502347\n",
            "epoch  60  loss =  1324.7172788651585\n",
            "epoch  61  loss =  1324.338226377841\n",
            "epoch  62  loss =  1323.967653333396\n",
            "epoch  63  loss =  1323.6053215435056\n",
            "epoch  64  loss =  1323.2509995923708\n",
            "epoch  65  loss =  1322.904462730265\n",
            "epoch  66  loss =  1322.565492756685\n",
            "epoch  67  loss =  1322.2338778948633\n",
            "epoch  68  loss =  1321.9094126592777\n",
            "epoch  69  loss =  1321.5918977175345\n",
            "epoch  70  loss =  1321.2811397479443\n",
            "epoch  71  loss =  1320.9769512938549\n",
            "epoch  72  loss =  1320.679150615769\n",
            "epoch  73  loss =  1320.3875615421073\n",
            "epoch  74  loss =  1320.1020133193633\n",
            "epoch  75  loss =  1319.8223404623232\n",
            "epoch  76  loss =  1319.5483826049374\n",
            "epoch  77  loss =  1319.2799843523253\n",
            "epoch  78  loss =  1319.0169951343373\n",
            "epoch  79  loss =  1318.7592690610636\n",
            "epoch  80  loss =  1318.5066647805613\n",
            "epoch  81  loss =  1318.2590453390787\n",
            "epoch  82  loss =  1318.0162780439923\n",
            "epoch  83  loss =  1317.7782343296112\n",
            "epoch  84  loss =  1317.544789625996\n",
            "epoch  85  loss =  1317.3158232309\n",
            "epoch  86  loss =  1317.0912181849126\n",
            "epoch  87  loss =  1316.870861149849\n",
            "epoch  88  loss =  1316.654642290433\n",
            "epoch  89  loss =  1316.4424551592763\n",
            "epoch  90  loss =  1316.234196585183\n",
            "epoch  91  loss =  1316.029766564714\n",
            "epoch  92  loss =  1315.8290681570456\n",
            "epoch  93  loss =  1315.6320073820368\n",
            "epoch  94  loss =  1315.4384931214852\n",
            "epoch  95  loss =  1315.2484370235486\n",
            "epoch  96  loss =  1315.061753410195\n",
            "epoch  97  loss =  1314.8783591877152\n",
            "epoch  98  loss =  1314.6981737601523\n",
            "epoch  99  loss =  1314.5211189456356\n",
            "epoch  100  loss =  1314.3471188955305\n",
            "epoch  101  loss =  1314.1761000162933\n",
            "epoch  102  loss =  1314.0079908940343\n",
            "epoch  103  loss =  1313.8427222216383\n",
            "epoch  104  loss =  1313.6802267284218\n",
            "epoch  105  loss =  1313.5204391122033\n",
            "epoch  106  loss =  1313.3632959737772\n",
            "epoch  107  loss =  1313.2087357536334\n",
            "epoch  108  loss =  1313.0566986709446\n",
            "epoch  109  loss =  1312.9071266646522\n",
            "epoch  110  loss =  1312.7599633366644\n",
            "epoch  111  loss =  1312.6151538970366\n",
            "epoch  112  loss =  1312.4726451111019\n",
            "epoch  113  loss =  1312.3323852484737\n",
            "epoch  114  loss =  1312.194324033846\n",
            "epoch  115  loss =  1312.0584125995476\n",
            "epoch  116  loss =  1311.9246034397665\n",
            "epoch  117  loss =  1311.7928503664164\n",
            "epoch  118  loss =  1311.663108466539\n",
            "epoch  119  loss =  1311.5353340612503\n",
            "epoch  120  loss =  1311.4094846661046\n",
            "epoch  121  loss =  1311.2855189528896\n",
            "epoch  122  loss =  1311.1633967127511\n",
            "epoch  123  loss =  1311.043078820628\n",
            "epoch  124  loss =  1310.9245272009434\n",
            "epoch  125  loss =  1310.807704794489\n",
            "epoch  126  loss =  1310.6925755264908\n",
            "epoch  127  loss =  1310.5791042757717\n",
            "epoch  128  loss =  1310.467256845023\n",
            "epoch  129  loss =  1310.356999932075\n",
            "epoch  130  loss =  1310.2483011022057\n",
            "epoch  131  loss =  1310.1411287613878\n",
            "epoch  132  loss =  1310.0354521304728\n",
            "epoch  133  loss =  1309.9312412202603\n",
            "epoch  134  loss =  1309.828466807433\n",
            "epoch  135  loss =  1309.7271004113218\n",
            "epoch  136  loss =  1309.6271142714577\n",
            "epoch  137  loss =  1309.5284813259098\n",
            "epoch  138  loss =  1309.4311751903267\n",
            "epoch  139  loss =  1309.3351701377371\n",
            "epoch  140  loss =  1309.2404410789936\n",
            "epoch  141  loss =  1309.1469635439082\n",
            "epoch  142  loss =  1309.0547136629943\n",
            "epoch  143  loss =  1308.9636681498519\n",
            "epoch  144  loss =  1308.8738042841178\n",
            "epoch  145  loss =  1308.785099894998\n",
            "epoch  146  loss =  1308.6975333453336\n",
            "epoch  147  loss =  1308.6110835162267\n",
            "epoch  148  loss =  1308.5257297921223\n",
            "epoch  149  loss =  1308.4414520464338\n",
            "epoch  150  loss =  1308.3582306275991\n",
            "epoch  151  loss =  1308.2760463456198\n",
            "epoch  152  loss =  1308.194880459025\n",
            "epoch  153  loss =  1308.1147146622607\n",
            "epoch  154  loss =  1308.0355310734778\n",
            "epoch  155  loss =  1307.9573122227434\n",
            "epoch  156  loss =  1307.880041040583\n",
            "epoch  157  loss =  1307.8037008469373\n",
            "epoch  158  loss =  1307.7282753404368\n",
            "epoch  159  loss =  1307.6537485880274\n",
            "epoch  160  loss =  1307.5801050149385\n",
            "epoch  161  loss =  1307.5073293949308\n",
            "epoch  162  loss =  1307.4354068408904\n",
            "epoch  163  loss =  1307.3643227957\n",
            "epoch  164  loss =  1307.2940630233793\n",
            "epoch  165  loss =  1307.224613600529\n",
            "epoch  166  loss =  1307.1559609080098\n",
            "epoch  167  loss =  1307.0880916229144\n",
            "epoch  168  loss =  1307.0209927107342\n",
            "epoch  169  loss =  1306.9546514178217\n",
            "epoch  170  loss =  1306.889055264037\n",
            "epoch  171  loss =  1306.8241920356486\n",
            "epoch  172  loss =  1306.7600497784242\n",
            "epoch  173  loss =  1306.6966167909425\n",
            "epoch  174  loss =  1306.633881618111\n",
            "epoch  175  loss =  1306.57183304486\n",
            "epoch  176  loss =  1306.5104600900422\n",
            "epoch  177  loss =  1306.4497520004948\n",
            "epoch  178  loss =  1306.3896982452945\n",
            "epoch  179  loss =  1306.330288510171\n",
            "epoch  180  loss =  1306.271512692075\n",
            "epoch  181  loss =  1306.2133608939416\n",
            "epoch  182  loss =  1306.1558234195563\n",
            "epoch  183  loss =  1306.098890768596\n",
            "epoch  184  loss =  1306.0425536318178\n",
            "epoch  185  loss =  1305.9868028863802\n",
            "epoch  186  loss =  1305.9316295912847\n",
            "epoch  187  loss =  1305.8770249829663\n",
            "epoch  188  loss =  1305.8229804710015\n",
            "epoch  189  loss =  1305.7694876339297\n",
            "epoch  190  loss =  1305.7165382152123\n",
            "epoch  191  loss =  1305.664124119282\n",
            "epoch  192  loss =  1305.6122374077195\n",
            "epoch  193  loss =  1305.5608702955271\n",
            "epoch  194  loss =  1305.5100151475158\n",
            "epoch  195  loss =  1305.459664474767\n",
            "epoch  196  loss =  1305.4098109312345\n",
            "epoch  197  loss =  1305.3604473103978\n",
            "epoch  198  loss =  1305.3115665420255\n",
            "epoch  199  loss =  1305.2631616890337\n",
            "epoch  200  loss =  1305.2152259444126\n",
            "epoch  201  loss =  1305.1677526282474\n",
            "epoch  202  loss =  1305.1207351848157\n",
            "epoch  203  loss =  1305.0741671797598\n",
            "epoch  204  loss =  1305.0280422973494\n",
            "epoch  205  loss =  1304.9823543377884\n",
            "epoch  206  loss =  1304.9370972146198\n",
            "epoch  207  loss =  1304.8922649521962\n",
            "epoch  208  loss =  1304.8478516831894\n",
            "epoch  209  loss =  1304.8038516462059\n",
            "epoch  210  loss =  1304.7602591834311\n",
            "epoch  211  loss =  1304.7170687383564\n",
            "epoch  212  loss =  1304.674274853552\n",
            "epoch  213  loss =  1304.6318721685022\n",
            "epoch  214  loss =  1304.5898554174948\n",
            "epoch  215  loss =  1304.5482194275705\n",
            "epoch  216  loss =  1304.5069591165113\n",
            "epoch  217  loss =  1304.4660694908962\n",
            "epoch  218  loss =  1304.4255456441988\n",
            "epoch  219  loss =  1304.3853827549199\n",
            "epoch  220  loss =  1304.345576084793\n",
            "epoch  221  loss =  1304.3061209770167\n",
            "epoch  222  loss =  1304.2670128545385\n",
            "epoch  223  loss =  1304.2282472183642\n",
            "epoch  224  loss =  1304.1898196459429\n",
            "epoch  225  loss =  1304.151725789565\n",
            "epoch  226  loss =  1304.113961374801\n",
            "epoch  227  loss =  1304.0765221989861\n",
            "epoch  228  loss =  1304.0394041297493\n",
            "epoch  229  loss =  1304.0026031035584\n",
            "epoch  230  loss =  1303.9661151243135\n",
            "epoch  231  loss =  1303.9299362619752\n",
            "epoch  232  loss =  1303.8940626512212\n",
            "epoch  233  loss =  1303.8584904901318\n",
            "epoch  234  loss =  1303.8232160389161\n",
            "epoch  235  loss =  1303.7882356186628\n",
            "epoch  236  loss =  1303.7535456101205\n",
            "epoch  237  loss =  1303.7191424525042\n",
            "epoch  238  loss =  1303.685022642344\n",
            "epoch  239  loss =  1303.6511827323372\n",
            "epoch  240  loss =  1303.6176193302488\n",
            "epoch  241  loss =  1303.5843290978287\n",
            "epoch  242  loss =  1303.551308749752\n",
            "epoch  243  loss =  1303.518555052582\n",
            "epoch  244  loss =  1303.486064823773\n",
            "epoch  245  loss =  1303.4538349306706\n",
            "epoch  246  loss =  1303.4218622895617\n",
            "epoch  247  loss =  1303.3901438647238\n",
            "epoch  248  loss =  1303.3586766675082\n",
            "epoch  249  loss =  1303.3274577554375\n",
            "epoch  250  loss =  1303.2964842313427\n",
            "epoch  251  loss =  1303.265753242472\n",
            "epoch  252  loss =  1303.2352619796927\n",
            "epoch  253  loss =  1303.2050076766288\n",
            "epoch  254  loss =  1303.1749876088913\n",
            "epoch  255  loss =  1303.1451990932735\n",
            "epoch  256  loss =  1303.115639486995\n",
            "epoch  257  loss =  1303.0863061869384\n",
            "epoch  258  loss =  1303.0571966289288\n",
            "epoch  259  loss =  1303.0283082870108\n",
            "epoch  260  loss =  1302.9996386727375\n",
            "epoch  261  loss =  1302.9711853345018\n",
            "epoch  262  loss =  1302.942945856843\n",
            "epoch  263  loss =  1302.914917859809\n",
            "epoch  264  loss =  1302.8870989982943\n",
            "epoch  265  loss =  1302.8594869614235\n",
            "epoch  266  loss =  1302.832079471935\n",
            "epoch  267  loss =  1302.804874285567\n",
            "epoch  268  loss =  1302.7778691904773\n",
            "epoch  269  loss =  1302.7510620066598\n",
            "epoch  270  loss =  1302.7244505853846\n",
            "epoch  271  loss =  1302.6980328086395\n",
            "epoch  272  loss =  1302.671806588587\n",
            "epoch  273  loss =  1302.6457698670408\n",
            "epoch  274  loss =  1302.6199206149386\n",
            "epoch  275  loss =  1302.5942568318346\n",
            "epoch  276  loss =  1302.5687765454052\n",
            "epoch  277  loss =  1302.543477810955\n",
            "epoch  278  loss =  1302.5183587109432\n",
            "epoch  279  loss =  1302.4934173545187\n",
            "epoch  280  loss =  1302.4686518770482\n",
            "epoch  281  loss =  1302.4440604396823\n",
            "epoch  282  loss =  1302.419641228903\n",
            "epoch  283  loss =  1302.3953924561072\n",
            "epoch  284  loss =  1302.3713123571606\n",
            "epoch  285  loss =  1302.3473991920116\n",
            "epoch  286  loss =  1302.3236512442616\n",
            "epoch  287  loss =  1302.3000668207897\n",
            "epoch  288  loss =  1302.276644251337\n",
            "epoch  289  loss =  1302.253381888146\n",
            "epoch  290  loss =  1302.2302781055785\n",
            "epoch  291  loss =  1302.2073312997447\n",
            "epoch  292  loss =  1302.184539888155\n",
            "epoch  293  loss =  1302.1619023093504\n",
            "epoch  294  loss =  1302.1394170225728\n",
            "epoch  295  loss =  1302.1170825074173\n",
            "epoch  296  loss =  1302.094897263499\n",
            "epoch  297  loss =  1302.0728598101323\n",
            "epoch  298  loss =  1302.050968686006\n",
            "epoch  299  loss =  1302.0292224488765\n",
            "epoch  300  loss =  1302.0076196752477\n",
            "epoch  301  loss =  1301.9861589600835\n",
            "epoch  302  loss =  1301.9648389165084\n",
            "epoch  303  loss =  1301.9436581755062\n",
            "epoch  304  loss =  1301.9226153856455\n",
            "epoch  305  loss =  1301.9017092128067\n",
            "epoch  306  loss =  1301.8809383398889\n",
            "epoch  307  loss =  1301.8603014665591\n",
            "epoch  308  loss =  1301.8397973089745\n",
            "epoch  309  loss =  1301.819424599536\n",
            "epoch  310  loss =  1301.7991820866257\n",
            "epoch  311  loss =  1301.7790685343564\n",
            "epoch  312  loss =  1301.759082722335\n",
            "epoch  313  loss =  1301.7392234454117\n",
            "epoch  314  loss =  1301.7194895134608\n",
            "epoch  315  loss =  1301.6998797511237\n",
            "epoch  316  loss =  1301.6803929976058\n",
            "epoch  317  loss =  1301.6610281064416\n",
            "epoch  318  loss =  1301.6417839452738\n",
            "epoch  319  loss =  1301.62265939565\n",
            "epoch  320  loss =  1301.603653352796\n",
            "epoch  321  loss =  1301.5847647254209\n",
            "epoch  322  loss =  1301.5659924355075\n",
            "epoch  323  loss =  1301.547335418111\n",
            "epoch  324  loss =  1301.5287926211697\n",
            "epoch  325  loss =  1301.5103630053047\n",
            "epoch  326  loss =  1301.4920455436356\n",
            "epoch  327  loss =  1301.4738392215868\n",
            "epoch  328  loss =  1301.4557430367158\n",
            "epoch  329  loss =  1301.437755998526\n",
            "epoch  330  loss =  1301.4198771282904\n",
            "epoch  331  loss =  1301.4021054588845\n",
            "epoch  332  loss =  1301.3844400346086\n",
            "epoch  333  loss =  1301.366879911018\n",
            "epoch  334  loss =  1301.3494241547783\n",
            "epoch  335  loss =  1301.332071843476\n",
            "epoch  336  loss =  1301.31482206548\n",
            "epoch  337  loss =  1301.297673919776\n",
            "epoch  338  loss =  1301.2806265158226\n",
            "epoch  339  loss =  1301.263678973385\n",
            "epoch  340  loss =  1301.2468304224021\n",
            "epoch  341  loss =  1301.2300800028327\n",
            "epoch  342  loss =  1301.2134268645204\n",
            "epoch  343  loss =  1301.1968701670398\n",
            "epoch  344  loss =  1301.1804090795679\n",
            "epoch  345  loss =  1301.1640427807476\n",
            "epoch  346  loss =  1301.1477704585518\n",
            "epoch  347  loss =  1301.1315913101532\n",
            "epoch  348  loss =  1301.1155045417916\n",
            "epoch  349  loss =  1301.0995093686556\n",
            "epoch  350  loss =  1301.0836050147445\n",
            "epoch  351  loss =  1301.0677907127572\n",
            "epoch  352  loss =  1301.0520657039658\n",
            "epoch  353  loss =  1301.036429238101\n",
            "epoch  354  loss =  1301.0208805732302\n",
            "epoch  355  loss =  1301.0054189756409\n",
            "epoch  356  loss =  1300.9900437197389\n",
            "epoch  357  loss =  1300.9747540879198\n",
            "epoch  358  loss =  1300.95954937048\n",
            "epoch  359  loss =  1300.9444288654927\n",
            "epoch  360  loss =  1300.929391878708\n",
            "epoch  361  loss =  1300.9144377234475\n",
            "epoch  362  loss =  1300.8995657205078\n",
            "epoch  363  loss =  1300.88477519805\n",
            "epoch  364  loss =  1300.8700654915083\n",
            "epoch  365  loss =  1300.8554359434895\n",
            "epoch  366  loss =  1300.8408859036736\n",
            "epoch  367  loss =  1300.8264147287261\n",
            "epoch  368  loss =  1300.8120217822009\n",
            "epoch  369  loss =  1300.7977064344477\n",
            "epoch  370  loss =  1300.7834680625274\n",
            "epoch  371  loss =  1300.7693060501151\n",
            "epoch  372  loss =  1300.7552197874195\n",
            "epoch  373  loss =  1300.7412086710947\n",
            "epoch  374  loss =  1300.7272721041604\n",
            "epoch  375  loss =  1300.713409495903\n",
            "epoch  376  loss =  1300.6996202618177\n",
            "epoch  377  loss =  1300.685903823506\n",
            "epoch  378  loss =  1300.6722596086079\n",
            "epoch  379  loss =  1300.6586870507253\n",
            "epoch  380  loss =  1300.645185589334\n",
            "epoch  381  loss =  1300.6317546697196\n",
            "epoch  382  loss =  1300.6183937428957\n",
            "epoch  383  loss =  1300.6051022655338\n",
            "epoch  384  loss =  1300.5918796998885\n",
            "epoch  385  loss =  1300.5787255137307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w2v.predict(\"가격\",10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Cy2EQCtCQx",
        "outputId": "2bbbe842-5872-4a96-f83a-4f14c276819f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['고장', '놀았는데', '작은', '저렴한듯', '하네요', '던져주니', '크지도', '사주려고', '삑', '뜯어']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Replace 'data.tsv' with the path to your TSV file\n",
        "tsv_file = '/content/drive/MyDrive/Coda_Result/2199261531.tsv'\n",
        "\n",
        "# Initialize an empty list to store the data from the TSV file\n",
        "data = []\n",
        "\n",
        "# Read the TSV file and store its content in the 'data' list\n",
        "with open(tsv_file, 'r', newline='', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file, delimiter='\\t')\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "\n",
        "df = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FnovnBdAgUpF",
        "outputId": "9efaf0b2-c86c-4d9d-960a-123e7c3cec36"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      user_id score       date  \\\n",
              "0   sati*****     5  23.08.01.   \n",
              "1      kb****     5  23.07.03.   \n",
              "2   kare*****     5  23.05.24.   \n",
              "3      cm****     5  23.05.18.   \n",
              "4    meji****     5  22.11.10.   \n",
              "..        ...   ...        ...   \n",
              "63   haha****     5  17.10.28.   \n",
              "64   haha****     5  17.10.28.   \n",
              "65  hyun*****     5  17.10.12.   \n",
              "66    ooy_***     5  17.10.20.   \n",
              "67  pine*****     5  17.10.15.   \n",
              "\n",
              "                                               review is_month is_repurch  \n",
              "0                                     진짜 귀얍게 잘 갖고 놀아요     True      False  \n",
              "1                         강아지 최애 공입니다. 노랑색을 유난히 좋아하네요     True      False  \n",
              "2   노견 푸들이 공놀이를 너무 좋아하는데 이빨이 약해서 탄탄한 공은 잘 못 물더라구요....    False      False  \n",
              "3                     저희 강아지가 진짜 좋아하는 공이라 여러개 샀는데 좋아요     True      False  \n",
              "4   온것중에 빨강이 골라서 줬는데 환장하구 놀아욤 !!\\n막 뜯어버리는 애도 아니고 짱...    False      False  \n",
              "..                                                ...      ...        ...  \n",
              "63  잘삿어요 이건 뜯지도 못하고 애들이 잘가지고 노네요 ㅎㅎ\\n잘산거같아요ㅎㅎ 견당 하...    False      False  \n",
              "64                                              만족합니다    False      False  \n",
              "65            너무너무 좋아하네요 5분만에 삑삑이 고장내고도 계속 가지고 놀아요 ^^    False      False  \n",
              "66                                배송도 빠르고 강아지가 좋아해요^^    False      False  \n",
              "67                                        배송도 빠르고 좋아요    False      False  \n",
              "\n",
              "[68 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-e8cef426-3800-4503-b984-017e393d7c08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>score</th>\n",
              "      <th>date</th>\n",
              "      <th>review</th>\n",
              "      <th>is_month</th>\n",
              "      <th>is_repurch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sati*****</td>\n",
              "      <td>5</td>\n",
              "      <td>23.08.01.</td>\n",
              "      <td>진짜 귀얍게 잘 갖고 놀아요</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kb****</td>\n",
              "      <td>5</td>\n",
              "      <td>23.07.03.</td>\n",
              "      <td>강아지 최애 공입니다. 노랑색을 유난히 좋아하네요</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kare*****</td>\n",
              "      <td>5</td>\n",
              "      <td>23.05.24.</td>\n",
              "      <td>노견 푸들이 공놀이를 너무 좋아하는데 이빨이 약해서 탄탄한 공은 잘 못 물더라구요....</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cm****</td>\n",
              "      <td>5</td>\n",
              "      <td>23.05.18.</td>\n",
              "      <td>저희 강아지가 진짜 좋아하는 공이라 여러개 샀는데 좋아요</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>meji****</td>\n",
              "      <td>5</td>\n",
              "      <td>22.11.10.</td>\n",
              "      <td>온것중에 빨강이 골라서 줬는데 환장하구 놀아욤 !!\\n막 뜯어버리는 애도 아니고 짱...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>haha****</td>\n",
              "      <td>5</td>\n",
              "      <td>17.10.28.</td>\n",
              "      <td>잘삿어요 이건 뜯지도 못하고 애들이 잘가지고 노네요 ㅎㅎ\\n잘산거같아요ㅎㅎ 견당 하...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>haha****</td>\n",
              "      <td>5</td>\n",
              "      <td>17.10.28.</td>\n",
              "      <td>만족합니다</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>hyun*****</td>\n",
              "      <td>5</td>\n",
              "      <td>17.10.12.</td>\n",
              "      <td>너무너무 좋아하네요 5분만에 삑삑이 고장내고도 계속 가지고 놀아요 ^^</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>ooy_***</td>\n",
              "      <td>5</td>\n",
              "      <td>17.10.20.</td>\n",
              "      <td>배송도 빠르고 강아지가 좋아해요^^</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>pine*****</td>\n",
              "      <td>5</td>\n",
              "      <td>17.10.15.</td>\n",
              "      <td>배송도 빠르고 좋아요</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8cef426-3800-4503-b984-017e393d7c08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-609960cd-91df-4cf6-8477-ce4205a4d241\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-609960cd-91df-4cf6-8477-ce4205a4d241')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-609960cd-91df-4cf6-8477-ce4205a4d241 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8cef426-3800-4503-b984-017e393d7c08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8cef426-3800-4503-b984-017e393d7c08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 말뭉치 생성\n",
        "corpus = \"-\".join(df['review'].tolist())\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "pX5r0ZLJmkFS",
        "outputId": "0f11cd04-4449-4117-9642-9ceaa65ffb6e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'진짜 귀얍게 잘 갖고 놀아요-강아지 최애 공입니다. 노랑색을 유난히 좋아하네요-노견 푸들이 공놀이를 너무 좋아하는데 이빨이 약해서 탄탄한 공은 잘 못 물더라구요. 그런데 어쩌다 이 공을 추천받아서 써보니 말랑하면서 잘 던져지고 내구성도 좋아서 엄청 오래쓰다가 새로 구입하게됐어요! 4개 구매하니 알아서 색별로 챙겨주셔서 너무 감사합니다~!-저희 강아지가 진짜 좋아하는 공이라 여러개 샀는데 좋아요-온것중에 빨강이 골라서 줬는데 환장하구 놀아욤 !!\\n막 뜯어버리는 애도 아니고 짱짱해서 오래 가지고 놀 것 같아 더 좋네요ㅎㅎ-가격만족 배송만족 제품만족-아주 잘 쓰고 있어요-뽁뽁이 소리나는 공을 좋아해서 늘 갖고 놀던 뽁뽁이 장난감이 소리가 안나서 가격도 저렴하고 해서 하나 구매해봤어요! 던져주니 아주 좋아해서 만족합니다! 그리고 라텍스 소재도 좋아서 인체에 무해할거 같아서 믿고 구매했어요^^-강아지가 젤 먼저 고른 장난감ㅋㅋㅋ 라텍스를 잘 좋아해용 굿-강아지 잘 가지고 놉니다  많이 파세요-삑삑이 소리나는 부분 납작한 곳이 있어서 구르다가 멈춰서 좋아요.-먼저 구매했었는데 좋아해서 재구매했어요.먼저구매한건 삑삑이가빠졌는데 새거오자마자 새거만  가지고노네요-삑삑ㅇㅣ 좋아해서 대량 구매해서 사용하고 있어요 \\n소리도 잘나고 모양다틀려서 너무 귀여워요-공 말랑말랑해서 잘 튀겨지고 아이도 좋아해요 생각보다는 크기가 작아요 테니스공보다 더 작아요-저번에 사서 너무 잘 가지고 놀았는데 어디로 갔는지 안보여서 사료 사면서 같이 주문했어요-이 제품은 잘믄들어진 공 입니다 추천~-늘 여기서 구매하네요 추천합니다-애기가 갑자기 너무 커서 작아져서 놀진 않지만 몇일 잘 가지구 놀았어요-배송도 빠르고 좋습니당-가격만족 제품만족 배송만족합니다-5살 푸들인데 너무 좋아하네요 안 놀아도 계속 물고 있거나 꼭 주위에 놓고 있네욯ㅎ-삑삑이 생각보다 튼튼해서 아직 잘 사용하고 있어요-삑삑소리 잘나서 강아지가 좋아해요~-사실 삑빅이 인형 다 터트려서 속에 삑삑이 대신으로 사고 있는데 그냥도 잘 가지고 놀아요.-공사랑은 어쩔수 없네요 ㅠ 진짜 안 사줬을 어쩔뻔 ㅎㅎ 하루종일 물고 다녀요 ㅎ-애들이너무만족하고좋아해요-상자 뜯으룯대부터 직접 와서 꺼내가더니 아주 공처돌이가 돼서 오늘 50번은 던지누것 같아요. 내구성은 써봐야 알겠지만 되게 좋아하네요. 탱탱한 게 아니라 말랑말랑한 공이고 삑삑 소리는 너무 크지 않아서 좋아요.-구매만족합니다 잘쓰고 있습니다-다른건 반응이없지만 공은 넘넘 잘가지고놀아요~-댕댕이들 잘 가지고 논다길래 상품평보고 샀는데 잘 노네요-잘가지고 놀아요 \\n색깔별로 보내주셔서 좋아요~-진짜 이거 주고나서부터 며칠동안 잠을 안자요..항상  가지고다녀요 ㅋㅋㅋ너무 귀여워 죽겟어요..-매번 주문합니다 오프라인보다 저렴한듯해요-귀여워요. 강아지가 좋아해서 추가 구매합니다.-재구매상품.삑소리가 망가져서\\n강아쥐가 젤 좋아하는공입니다-공놀이할때 좋을거같아요-작아서 입에 쏙 들어가니까 더 좋아하는거 같아요.\\n(귀여우니까 저희집 강아지 봐주세요)-한통 시켜버렸어요 실버푸들 키우는데 워낙 작은편이라 작은공만 좋아하는데 너무 작지도않고 크지도않도 너무 잘가지고 놀아요 이공만가지고 놀아요 ㅠㅠ-너무 좋아해요! 어떤걸 골라야하는지 모르겠대요-오 애들이 넘 잘가지고 노네용ㅎ\\n또 구매할께요-좋은 상품 항상 감사합니다-너무 잘먹어서 좋아요-완전 기여워요 ㅋ케-배송도 빠르도 제품도 좋습니다-공놀이좋아해서 여러개주문했어요-튼튼한데도 하루만에 아작이 났네요. 잘 놀았어요 ㅋㅋㅋ-좀 더 딴딴한 라텍스를 원했는데 요 장난감도 살짝 부드럽네요ㅎㅎ 그래도 저희집 댕댕이는 너무 좋아합니다😆-강아지가 좋아하고 잘 가지고놀아요-아이가 빡삑이 공을 좋아해서 종류별로 자주 구매해줍니다-있던거 잊어버려서 여러개 구매했네요 -좋아용 ㅎㅎㅎ-저렴하게 잘 샀습니다. -만족합니다-적극추천합니다 강아지가너무좋아합니다재구매의사도있습니다제품좋습니다배송도빠릅니다추천합니다만족합니다배송도빠릅니다추천합니다-공장난감 너무좋아해서 사줬더니 하루종일 이거가지고 놀아달라네요ㅋㅈㅋ-대만족합니다 강아지가 너무좋아합니다^^일반샵에서는 3-4천원에 판매하는걸로 알고있습니다.대만족이구요, 추천합니다배송도 빠르구요 포장상태도 좋습니다-대만족입니다^^-던지고 물고 엄청 좋아해요.-만족합니다-소리나는 장난감 100일 지난 토이푸들 아이에게 장난감을 많이 사주려고 시켰는데ᆢ소리 나니 좋아요\\n조금 딱딱함-만득이만큼 좋아합니다. 작아서 입에 쏙 물리네요.-삑삐호리나요-좋아요 강아지가 잘 가지고 노네요 배송도 빠르고 좋아요 그런데 공 크키가 좀 작은 편이라 소형견들이 가지고놀기에 좋아요-잘삿어요 이건 뜯지도 못하고 애들이 잘가지고 노네요 ㅎㅎ\\n잘산거같아요ㅎㅎ 견당 하나씩인데 독차지하네요-만족합니다-너무너무 좋아하네요 5분만에 삑삑이 고장내고도 계속 가지고 놀아요 ^^-배송도 빠르고 강아지가 좋아해요^^-배송도 빠르고 좋아요'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "training_data = []\n",
        "sentences = corpus.split(\"-\")\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "      sentences[i] = sentences[i].strip()\n",
        "      words_and_tags = okt.pos(sentences[i])\n",
        "\n",
        "      filtered_words = [word for word, tag in words_and_tags\n",
        "                        if tag in ['Noun', 'Verb', 'Adjective']\n",
        "                        and word not in stop_words]\n",
        "\n",
        "      x = [word.strip(string.punctuation) for word in filtered_words]\n",
        "      x = [word for word in filtered_words if len(x) > 1]\n",
        "      training_data.append(x)\n",
        "\n",
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0jhY426oNmn",
        "outputId": "1f2391aa-8a50-4dcb-a861-4d67d4fc4303"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['진짜', '귀얍', '잘', '갖고', '놀아요'],\n",
              " ['강아지', '최애', '공', '입니다', '노랑', '색', '좋아하네요'],\n",
              " ['노견',\n",
              "  '푸',\n",
              "  '들이',\n",
              "  '놀이',\n",
              "  '좋아하는데',\n",
              "  '이빨',\n",
              "  '약해서',\n",
              "  '탄탄한',\n",
              "  '공',\n",
              "  '잘',\n",
              "  '못',\n",
              "  '물더라구요',\n",
              "  '이',\n",
              "  '공',\n",
              "  '추천',\n",
              "  '받아서',\n",
              "  '써',\n",
              "  '보니',\n",
              "  '말랑하면서',\n",
              "  '잘',\n",
              "  '던져지고',\n",
              "  '구성',\n",
              "  '좋아서',\n",
              "  '쓰다가',\n",
              "  '새로',\n",
              "  '구입',\n",
              "  '하게',\n",
              "  '됐어요',\n",
              "  '개',\n",
              "  '구매',\n",
              "  '하니',\n",
              "  '알아서',\n",
              "  '색',\n",
              "  '별로',\n",
              "  '챙겨주셔서',\n",
              "  '감사합니다'],\n",
              " ['저희', '강아지', '진짜', '좋아하는', '공이', '개', '샀는데', '좋아요'],\n",
              " ['것',\n",
              "  '빨강이',\n",
              "  '골',\n",
              "  '줬는데',\n",
              "  '환장하구',\n",
              "  '놀아욤',\n",
              "  '막',\n",
              "  '뜯어',\n",
              "  '버리는',\n",
              "  '애도',\n",
              "  '아니고',\n",
              "  '짱짱해서',\n",
              "  '가지',\n",
              "  '놀',\n",
              "  '것',\n",
              "  '같아',\n",
              "  '더',\n",
              "  '좋네요'],\n",
              " ['가격', '만족', '배송', '만족', '제품', '만족'],\n",
              " ['아주', '잘', '쓰고', '있어요'],\n",
              " ['뽁뽁',\n",
              "  '리나',\n",
              "  '공',\n",
              "  '좋아해서',\n",
              "  '늘',\n",
              "  '갖고',\n",
              "  '놀던',\n",
              "  '뽁뽁',\n",
              "  '장난감',\n",
              "  '소리',\n",
              "  '안나',\n",
              "  '가격',\n",
              "  '저렴하고',\n",
              "  '해서',\n",
              "  '하나',\n",
              "  '구매',\n",
              "  '해봤어요',\n",
              "  '던져주니',\n",
              "  '아주',\n",
              "  '좋아해서',\n",
              "  '만족합니다',\n",
              "  '라텍스',\n",
              "  '소재',\n",
              "  '좋아서',\n",
              "  '인체',\n",
              "  '무',\n",
              "  '해',\n",
              "  '할거',\n",
              "  '같아서',\n",
              "  '믿고',\n",
              "  '구매',\n",
              "  '했어요'],\n",
              " ['강아지', '젤', '먼저', '고른', '장난감', '라텍스', '잘', '좋아해용', '굿'],\n",
              " ['강아지', '잘', '가지', '놉니다', '파세요'],\n",
              " ['삑삑', '리나', '부분', '납작한', '곳', '있어서', '구르다가', '멈춰서', '좋아요'],\n",
              " ['먼저',\n",
              "  '구매',\n",
              "  '했었는데',\n",
              "  '좋아해서',\n",
              "  '재구매',\n",
              "  '했어요',\n",
              "  '먼저',\n",
              "  '구매',\n",
              "  '건',\n",
              "  '삑삑',\n",
              "  '가빠졌는데',\n",
              "  '새거오자마자',\n",
              "  '거만',\n",
              "  '가지',\n",
              "  '노네요'],\n",
              " ['삑삑',\n",
              "  '좋아해서',\n",
              "  '대량',\n",
              "  '구매',\n",
              "  '해서',\n",
              "  '사용',\n",
              "  '있어요',\n",
              "  '소리',\n",
              "  '잘나고',\n",
              "  '모',\n",
              "  '틀려서',\n",
              "  '귀여워요'],\n",
              " ['공',\n",
              "  '말랑말랑해서',\n",
              "  '잘',\n",
              "  '튀겨지고',\n",
              "  '아이',\n",
              "  '좋아해요',\n",
              "  '생각',\n",
              "  '크기',\n",
              "  '작아요',\n",
              "  '테니스공',\n",
              "  '더',\n",
              "  '작아요'],\n",
              " ['저번', '사서', '잘', '가지', '놀았는데', '어디', '갔는지', '안보', '사료', '사면', '주문', '했어요'],\n",
              " ['이', '제품', '잘', '믄', '들어진', '공', '입니다', '추천'],\n",
              " ['늘', '여기', '구매', '하네요', '추천', '합니다'],\n",
              " ['애기', '갑자기', '커서', '작아져서', '놀진', '않지만', '일', '잘', '가지구', '놀았어요'],\n",
              " ['배송', '빠르고', '좋', '습', '니당'],\n",
              " ['가격', '만족', '제품', '만족', '배송', '만족합니다'],\n",
              " ['살',\n",
              "  '푸',\n",
              "  '들인데',\n",
              "  '좋아하네요',\n",
              "  '안',\n",
              "  '놀아도',\n",
              "  '계속',\n",
              "  '물',\n",
              "  '있거나',\n",
              "  '꼭',\n",
              "  '주위',\n",
              "  '놓고',\n",
              "  '있네욯'],\n",
              " ['삑삑', '생각', '튼튼해서', '잘', '사용', '있어요'],\n",
              " ['삑삑', '소리', '잘나서', '강아지', '좋아해요'],\n",
              " ['사실',\n",
              "  '삑빅',\n",
              "  '인형',\n",
              "  '터트려',\n",
              "  '속',\n",
              "  '삑삑',\n",
              "  '대신',\n",
              "  '사고',\n",
              "  '있는데',\n",
              "  '그냥',\n",
              "  '잘',\n",
              "  '가지',\n",
              "  '놀아요'],\n",
              " ['공사', '수', '없네요', '진짜', '안', '사줬을', '뻔', '하루', '종일', '물', '다녀요'],\n",
              " ['애', '만족하고', '좋아해요'],\n",
              " ['상자',\n",
              "  '뜯으',\n",
              "  '룯',\n",
              "  '직접',\n",
              "  '와서',\n",
              "  '꺼내가더니',\n",
              "  '아주',\n",
              "  '공처',\n",
              "  '돌이',\n",
              "  '돼서',\n",
              "  '오늘',\n",
              "  '번은',\n",
              "  '던',\n",
              "  '지누',\n",
              "  '것',\n",
              "  '같아요',\n",
              "  '구성은',\n",
              "  '써',\n",
              "  '봐야',\n",
              "  '알겠지만',\n",
              "  '좋아하네요',\n",
              "  '탱탱한',\n",
              "  '게',\n",
              "  '아니라',\n",
              "  '말랑말랑한',\n",
              "  '공이',\n",
              "  '삑삑',\n",
              "  '소리',\n",
              "  '크지',\n",
              "  '않아서',\n",
              "  '좋아요'],\n",
              " ['구매', '만족합니다', '잘쓰고', '있습니다'],\n",
              " ['다른건', '반응', '없지만', '공', '넘', '넘', '잘가지고', '놀아요'],\n",
              " ['댕댕', '들', '잘', '가지', '논다길래', '상품', '평보', '샀는데', '잘', '노네요'],\n",
              " ['잘가지고', '놀아요', '색깔', '별로', '보내주셔서', '좋아요'],\n",
              " ['진짜',\n",
              "  '거',\n",
              "  '주고',\n",
              "  '나서부터',\n",
              "  '며칠',\n",
              "  '동안',\n",
              "  '잠',\n",
              "  '안자요',\n",
              "  '항상',\n",
              "  '가지',\n",
              "  '다녀요',\n",
              "  '귀여워',\n",
              "  '죽겟어요'],\n",
              " ['매번', '주문', '합니다', '오프라인', '저렴한듯', '해'],\n",
              " ['귀여워요', '강아지', '좋아해서', '추가', '구매', '합니다'],\n",
              " ['재구매', '상품', '삑', '소리', '망가져서', '강', '쥐', '젤', '좋아하는', '공', '입니다'],\n",
              " ['놀이', '할', '때', '좋을거', '같아요'],\n",
              " ['작아서', '입', '쏙', '들어가니까', '더', '좋아하는거', '같아요', '여우', '집', '강아지', '봐주세요'],\n",
              " ['통',\n",
              "  '시켜',\n",
              "  '버렸어요',\n",
              "  '실버',\n",
              "  '푸',\n",
              "  '들',\n",
              "  '키우는데',\n",
              "  '워낙',\n",
              "  '작은',\n",
              "  '편이',\n",
              "  '은공',\n",
              "  '좋아하는데',\n",
              "  '지도',\n",
              "  '않고',\n",
              "  '크지도',\n",
              "  '않도',\n",
              "  '잘가지고',\n",
              "  '놀아요',\n",
              "  '만가',\n",
              "  '지고',\n",
              "  '놀아요'],\n",
              " ['좋아해요', '걸', '골라야하는지', '모르겠', '대요'],\n",
              " ['오', '애', '넘', '잘가지고', '노', '용', '또', '구매', '할께요'],\n",
              " ['좋은', '상품', '항상', '감사합니다'],\n",
              " ['먹어서', '좋아요'],\n",
              " ['완전', '기여', '워', '케'],\n",
              " ['배송', '빠르도', '제품', '좋습니다'],\n",
              " ['놀이', '좋아해서', '개', '주문', '했어요'],\n",
              " ['튼튼한데도', '하루', '아작이', '났네요', '잘', '놀았어요'],\n",
              " ['좀',\n",
              "  '더',\n",
              "  '딴딴한',\n",
              "  '라텍스',\n",
              "  '원했는데',\n",
              "  '요',\n",
              "  '장난감',\n",
              "  '살짝',\n",
              "  '부드럽네요',\n",
              "  '집',\n",
              "  '댕댕',\n",
              "  '좋아합니다'],\n",
              " ['강아지', '좋아하고', '잘', '가지', '놀아요'],\n",
              " ['아이', '빡삑', '공', '좋아해서', '종류', '별로', '자주', '구매', '해줍니다'],\n",
              " ['있던거', '잊어버려서', '개', '구매', '했네요'],\n",
              " [],\n",
              " ['저렴하게', '잘', '샀습니다'],\n",
              " [],\n",
              " ['적극',\n",
              "  '추천',\n",
              "  '합니다',\n",
              "  '강아지',\n",
              "  '좋아합니다',\n",
              "  '재구매',\n",
              "  '의사',\n",
              "  '있습니다',\n",
              "  '제품',\n",
              "  '좋습니다',\n",
              "  '배송',\n",
              "  '빠릅니다',\n",
              "  '추천',\n",
              "  '합니다',\n",
              "  '만족합니다',\n",
              "  '배송',\n",
              "  '빠릅니다',\n",
              "  '추천',\n",
              "  '합니다'],\n",
              " ['장난감', '좋아해서', '사줬더니', '하루', '종일', '거가', '지고', '놀아', '달라네요'],\n",
              " ['대', '만족합니다', '강아지', '좋아합니다', '일반'],\n",
              " ['판매',\n",
              "  '는걸',\n",
              "  '알고있습니다',\n",
              "  '만족',\n",
              "  '이구',\n",
              "  '추천',\n",
              "  '합니다',\n",
              "  '배송',\n",
              "  '빠르구요',\n",
              "  '포장',\n",
              "  '상태',\n",
              "  '좋습니다'],\n",
              " ['만족', '입니다'],\n",
              " ['던지고', '물', '좋아해요'],\n",
              " [],\n",
              " ['리나',\n",
              "  '장난감',\n",
              "  '지난',\n",
              "  '토이',\n",
              "  '푸',\n",
              "  '들',\n",
              "  '아이',\n",
              "  '장난감',\n",
              "  '사주려고',\n",
              "  '시켰는데',\n",
              "  '소리',\n",
              "  '나니',\n",
              "  '좋아요',\n",
              "  '조금',\n",
              "  '딱딱함'],\n",
              " ['만득이', '좋아합니다', '작아서', '입', '쏙', '물리네요'],\n",
              " ['삑삐', '호리나요'],\n",
              " ['좋아요',\n",
              "  '강아지',\n",
              "  '잘',\n",
              "  '가지',\n",
              "  '노네요',\n",
              "  '배송',\n",
              "  '빠르고',\n",
              "  '좋아요',\n",
              "  '공',\n",
              "  '크',\n",
              "  '키',\n",
              "  '좀',\n",
              "  '작은',\n",
              "  '편이',\n",
              "  '소형견',\n",
              "  '가지',\n",
              "  '놀기에',\n",
              "  '좋아요'],\n",
              " ['잘삿어',\n",
              "  '이건',\n",
              "  '뜯지도',\n",
              "  '못',\n",
              "  '애',\n",
              "  '잘가지고',\n",
              "  '노네요',\n",
              "  '잘산거',\n",
              "  '같아요',\n",
              "  '견당',\n",
              "  '하나',\n",
              "  '독차지',\n",
              "  '하네요'],\n",
              " [],\n",
              " ['좋아하네요', '삑삑', '고장', '고도', '계속', '가지', '놀아요'],\n",
              " ['배송', '빠르고', '강아지', '좋아해요'],\n",
              " ['배송', '빠르고', '좋아요']]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rK8xHnXNr0w9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}